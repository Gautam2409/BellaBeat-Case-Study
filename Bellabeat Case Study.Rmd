---
title: "Bellabeat Case Study"
author: "Gautam Singh"
date: "20/09/2021"
output: html_document
---

## INTRODUCTION

This case study is the Capstone Project of Google Data Analytics Professional Certificate. The Case Study entails all 6 steps of Data Analysis and is aimed at **How Can A Wellness Technology Company (Bellabeat) Play It Smart?**

Bellabeat is a high-tech manufacturer of beautifully-designed health-focused smart products for women since 2013. Inspiring and empowering women with knowledge about their own health and habits, Bellabeat has grown rapidly and quickly positioned itself as a tech-driven wellness company for females

## BUSINESS TASK

Analyze FitBit Fitness Tracker Data to gain insights into how consumers are using the FitBit App and discover trends and insights for Bellabeat Marketing Strategy.

**Key Stakeholders for the project are** :

  1. *Urska Srsen*: Bellabeat's Co-Founder and Chief Creative Officer
  2. *Sando Mur*: Mathematician, Bellabeat's Co-Founder and key member of Bellabeat Executive Team
  3. *Bellabeat Marketing Analytics Team*: A team of data analysts guiding Bellabeat's Marketing Strategy.
  
## DATASET

The [dataset](https://www.kaggle.com/arashnic/fitbit) is publicly available on Kaggle and contains personal fitness tracker data from **30 FitBit users**. The data has been stored across 18 CSV files. 

The dataset was generated by respondents from a distributed survey via Amazon Mechanical Turk between 12 March, 2016 to 12 May, 2016. Under this, 30 eligible FitBit users were consented to the submission of personal tracker data, including:
  1. Minute-level output for physical activity,
  2. Heart rate,
  3. Sleep monitoring,
  4. Daily activity,
  5. Steps,

that can be used to explore users' habits.

### Limitations of Data Set:

1. The Data was collected in 2016 and since then Users' daily activity, fitness, sleeping habits, diet, and food consumption may have changed.
2. Sample size of just 30 Female FitBit users is not representative of the entire Female population.
3. As the data was collected in a survey, hence there is no way to ascertain the integrity and accuracy of the data.

### ROCCC Test of the Data Set

ROCCC stands for **R**eliable, **O**riginal, **C**omprehensive, **C**urrent, and **C**ited.

  1. *Reiable*: Not reliable as it only has 30 respondents (LOW)
  2. *Original*: Third Party Provider (LOW)
  3. *Comprehensive*: Parameters match most of Bellabeat's products' parameters (MED)
  4. *Current*: Data is 5 years old and less relevant in today's scenarios (LOW)
  5. *Cited*: Data was collected from a third party, hence unknown (LOW)
  
Hence, based on the ROCCC test the Data Set can be deemed to be of bad quality and is not recommended to produce business recommendations based on this data


## PROCESSING DATA

### Loading Libraries

```{r Loading Libraries, message=FALSE, warning=FALSE}
library(tidyverse)
library(skimr)
```

The above libraries can be loaded only upon installation

### Importing Data Set

Initially we will import the dailyActivity_merged.csv file which is one of the 18 csv files available and store it as a **data frame**, daily_activity.

```{r Loading Data Set, message=FALSE, warning=FALSE}
daily_activity = read_csv('C:/Users/user/Desktop/BellaBeat - Analytics Case Study/Fitabase Data 4.12.16-5.12.16/dailyActivity_merged.csv')
```

### Data Cleaning Process

**STEP 1:** Observing and familiarizing with the date

 * We will begin by viewing the data frame, first 6 rows of it using the head() function to get an overview of the data
    
```{r View Data, message=FALSE, warning=FALSE}
head(daily_activity)
```
    
 * We can obtaine further information regarding the data using the colnames() and the glimpse() function
    
```{r Column Names, message=FALSE, warning=FALSE}
colnames(daily_activity)
```
    
```{r Data Glimpse, message=FALSE, warning=FALSE}
glimpse(daily_activity)
```

Hence we can conclude that in the daily_activity data frame there are 15 columns and 940 rows/entries.

There is an anomaly which has been exposed by the above function, the *ActivityDate* column/variable has been wrongly classified as the *object* data type whereas it should have been *datetime* data type and hence needs conversion. 

Through the problem statement we know that the data holds activities of 30 different women. This fact can be reiterated by uniquely counting the **Id** column.

```{r Calculate Unique Users, message=FALSE, warning=FALSE}
sapply(daily_activity, function(x) length(unique(x)))
```

Hence after doing the sanity check we can say that the metadata was wrong and the daily_activity data frame holds the info of 33 female users rather than 30.

**STEP 2:** Check for missing or null values

```{r Check for Missing Values, message=FALSE, warning=FALSE}
table(is.na(daily_activity))
```

Here the function returns **FALSE** hence there are no missing or null values present in the entire data frame. We can also have a lookout for missing or null values row-wise and for each column as well:

 * Row-Wise:
```{r Check for Missing Values - Rows, message=FALSE, warning=FALSE}
rowSums(is.na(daily_activity))
```

 * Column-Wise:
```{r Check for Missing Values - Columns, message=FALSE, warning=FALSE}
sapply(daily_activity, function(x) sum(is.na(x)))
```

### Data Manipulation

1. As noted above, the *ActivityDate* column has been assigned the wrong data type, hence we would have to convert it from object to datetime. While doing so we can also convert the date format in *yyyy-mm-dd* format for better understanding

```{r Change Date Data Type and Format, message=FALSE, warning=FALSE}
daily_activity[['ActivityDate']] <- as.POSIXct(daily_activity[['ActivityDate']], format = "%m/%d/%Y")
```

Now we can check whether the required changes have been made or not?

```{r Glimpse Data 1, message=FALSE, warning=FALSE}
glimpse(daily_activity)
```

Therefore, we have successfully made the aforementioned changes.

2. Create a new column *DayOfTheWeek* from the ActivityDate column:

```{r Get Day Name, message=FALSE, warning=FALSE}
daily_activity <- daily_activity %>% 
                    mutate(DayOfWeek = weekdays(ActivityDate))

daily_activity <- daily_activity %>% 
                    relocate(DayOfWeek, .before = TotalSteps)

glimpse(daily_activity)
```

Hence, we have successfully extracted the name of the day from the date provided which would aid us in recognizing weekly patterns for a particular day.

3. Create a new column, *TotalMins* which would be the sum of VeryActiveMinutes, FailyActiveMinutes, LightlyActiveMinutes, and SedentaryMinutes. Similary we would also create a column to give us *TotalHours* from the total minutes column itself to give us a better understanding:

```{r Get Total Activity Minutes, message=FALSE, warning=FALSE}
daily_activity <- daily_activity %>% 
                    mutate(TotalMins = VeryActiveMinutes + FairlyActiveMinutes + LightlyActiveMinutes + SedentaryMinutes)


daily_activity <- daily_activity %>% 
                    mutate(TotalHours = TotalMins/60)

glimpse(daily_activity)
```

Thus, we have created the two columns successfully as well and now we would move onto the analyzing phase

## ANALYZE

We would be pulling out some important characteristics of the daily_activity data frame to perform analysis:

* Count number of rows,
* Mean,
* Standard Deviation,
* Minimum,
* Maximum, and
* Percentiles (25%, 50%, 75%)

```{r Summarize Data, message=FALSE, warning=FALSE}
summary(daily_activity)
```

The foolowing interpretations could be frawn from these statistical findings:

1. On an average, users logged 7,638 steps or 5.475kms which is below par. As recommended by Centre for Disease Control, USA, and adult female has to aim at least 10,000 steps or 8kms per day to benefit from general health, weight loss, and fitness improvement. [Source](https://www.medicalnewstoday.com/articles/how-many-steps-should-you-take-a-day)

2. Sedentary users are the majority logging on an average 991.2 minutes or 16.52 hours making up 81.33% of the total average minutes.

3. The average calories burnt were 2304 which is equivalent to almost 0.6 pounds couldn't be interpreted into detail as calories burned depend on several factors such as age, weight, daily tasks, exercise, hormones, and daily calorie intake. [Source](https://www.healthline.com/health/fitness-exercise/how-many-calories-do-i-burn-a-day#Burning-calories)

## VISUALIZATION

**FREQUENCY OF USAGE ACROSS THE WEEK**

```{r Bar Chart, message=FALSE, warning=FALSE}
ggplot(data = daily_activity) + geom_bar(mapping = aes(x = DayOfWeek)) + labs(title = "No. of times users logged in app across the week", x = "Day of the Week", y = "Frequency")
```

1. It can be stated that the users prefer or remember to track their activity more often on the app during the midweek i.e., from Tuesday to Friday.

2. The frequency then drops on Friday and continues dropping across the weekends and Monday.

**CALORIES BURNED FOR EVERY STEP TAKEN**

```{r Scatter Plot, message=FALSE, warning=FALSE}
caloriestepplot <- ggplot(daily_activity) + geom_point(mapping = aes(x = TotalSteps, y = Calories, color = TotalSteps)) + labs(title = "Calories burned for every step taken", x = "Steps Taken", y = "Calories Burned")

print(caloriestepplot + scale_colour_gradient(low = "red", high = "green"))
```

```{r Line Chart, message=FALSE, warning=FALSE}
ggplot(daily_activity) + geom_smooth(mapping = aes(x = TotalSteps, y = Calories)) + labs(title = "Calories burned for every step taken", x = "Steps Taken", y = "Calories Burned")
```

The above two plots depict:

1. A positive correlation between total steps and calories burned.

2. The intensity of calories burned increase when users are at the range of > 0 to 15,000 steps with calories burn rate cooling down from 15,000 steps onwards.

3. A few outliers were also observed:

 * 0 steps with 0 to minimal calories burned.
 * 1 observation of > 35,000 steps with < 3,000 calories burned.

  The oyrliers could be due to natural variation of data, change in user's usage or errirs in data collection (i.e., miscalculations, data containment or human error).
  
**CALOROES BURNED FOR EVERY HOUR LOGGED**

```{r Scatter Plot 1, message=FALSE, warning=FALSE}
calorieshour <- ggplot(data = daily_activity) + geom_point(mapping = aes(x = TotalHours, y = Calories, color = Calories)) + labs(title = "Calories burned for every hour logged", x = "Hours Logged", y = "Calories Burned")

print(calorieshour + scale_colour_gradient(low = "red", high = "green"))
```

```{r Line Chart 1, message=FALSE, warning=FALSE}
ggplot(data = daily_activity) + geom_smooth(mapping = aes(x = TotalHours, y = Calories, color = Calories)) + labs(title = "Calories burned for every hour logged", x = "Hours Logged", y = "Calories Burned")
```

The above two plots depict:

1. A weak postive correlation whereby the increase of hours logged does not translate into more calories being burned.

2. A few outliers were also observed:

 * The same zero value outliers as mentioned above.
 * An unusual red dot at the 24 hours with zero calorie burned which may be due to the same reasons as stated above.
 
**PERCENTAGE OF ACTIVITY IN MINUTES**

```{r Data Preparation for Pie Chart, message=FALSE, warning=FALSE}
very_active_minutes <- sum(daily_activity$VeryActiveMinutes)
fairly_active_minutes <- sum(daily_activity$FairlyActiveMinutes)
lightly_active_minutes <- sum(daily_activity$LightlyActiveMinutes)
sedentary_minutes <- sum(daily_activity$SedentaryMinutes)
total_mins <- sum(daily_activity$TotalMins)

df.data <- data.frame( class = c("very_active_mins", "fairly_active_mins", "lightly_active_mins", "sedentary_mins"), mins = c(very_active_minutes, fairly_active_minutes, lightly_active_minutes, sedentary_minutes))

df.data
```

```{r Percentage Activity, message=FALSE, warning=FALSE}
df.data <- df.data %>% 
            mutate(percentage = (mins/total_mins)*100)

df.data
```

```{r Pie Chart, message=FALSE, warning=FALSE}
ggplot(df.data, aes(x = "", y = percentage, fill = class)) + geom_bar(width = 1, stat = "identity", color = "white") + coord_polar("y", start = 0) + scale_fill_brewer() + labs(title = "Percentage of Activity in Minutes")
```

The above plot depicts:

1. Sedentary Minutes takes the biggest slice at 81.3%

2. This indicates that the users are using the FitBit app to log daily activities such as daily commute, inactive movements (moving from one spot to another) or running errands.

3. App is rarely being used to track fitness (i.e., running) as per the minor percentage of fairly active activity (1.1%) and very active activity (1.7%). This is highly discouraging as FitBit app was developed to encourage fitness.

## ACT

**TRENDS IDENTIFIED**

* Majority of users (81.3%) are using the FitBit app to track sedentary activities and not using it for tracking their health habits.

* Users prefer to track their activities during the weekdays as compared to weekends - perhaps because they spend more time outside on weekdays and stay in on weekends.

**USING THESE TRENDS TO AID BELLABEAT'S MARKETING STRATEGY**

* Bellabeat marketing team can encourage users by educationg and equipping them with knwoledge about fitness benefits, suggest different types of exercise (i.e., simple 10 minutes exercise on weekday and a more intense exercise on weekends) and calories intake and burnt rate information on the Bellbeat app.

* On weekends, Bellabeat app can also prompt notification to encourage users to exercise.

* Bellabeat could create a platform on the app where in friends could compete regarding the steps taken by each individual being ranked on a daily basis, and some in app credits based on > 10,000 steps a day.